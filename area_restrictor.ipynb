{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cfbad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import pyarrow\n",
    "import pyarrow.parquet\n",
    "from sklearn.cluster import KMeans\n",
    "from shapely.geometry import Point, Polygon\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8e7740",
   "metadata": {},
   "source": [
    "## FUNCTIONS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499aabc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_cleaning_pipeline(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    df = df[df[\"Type of mobile\"].isin([\"Class A\", \"Class B\"])].drop(columns=[\"Type of mobile\"])\n",
    "\n",
    "    df = df.rename(columns={\"# Timestamp\": \"Timestamp\"})\n",
    "    df[\"Timestamp\"] = pd.to_datetime(df[\"Timestamp\"], format=\"%d/%m/%Y %H:%M:%S\", errors=\"coerce\")\n",
    "\n",
    "    df = df.drop_duplicates([\"Timestamp\", \"MMSI\", ], keep=\"first\")\n",
    "    df = df.drop(columns=df.columns[-5:])\n",
    "\n",
    "    knots_to_ms = 0.514444\n",
    "    df[\"SOG\"] = knots_to_ms * df[\"SOG\"]\n",
    "    \n",
    "    return df\n",
    "    \n",
    "def quick_summary(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Generate a quick summary of the AIS data in the DataFrame.\n",
    "    Args:\n",
    "        df: DataFrame with AIS data, must contain 'MMSI', 'Timestamp', 'Latitude', 'Longitude' columns.\n",
    "        \n",
    "    Returns:\n",
    "        None: Prints summary statistics.\n",
    "        \"\"\"\n",
    "    # Number of unique vessels\n",
    "    num_vessels = int(df['MMSI'].nunique())\n",
    "    df = df.rename(columns={\"# Timestamp\": \"Timestamp\"})\n",
    "    df[\"Timestamp\"] = pd.to_datetime(df[\"Timestamp\"], format=\"%d/%m/%Y %H:%M:%S\", errors=\"coerce\")\n",
    "\n",
    "    # Spatial extent\n",
    "    lat_min, lat_max = df['Latitude'].min(), df['Latitude'].max()\n",
    "    lon_min, lon_max = df['Longitude'].min(), df['Longitude'].max()\n",
    "    centroid_lat, centroid_lon = df['Latitude'].mean(), df['Longitude'].mean()\n",
    "\n",
    "    # Messages per vessel\n",
    "    msgs_per_vessel = df.groupby('MMSI').size()\n",
    "    msgs_stats = msgs_per_vessel.describe().to_dict()\n",
    "    top_10_vessels = msgs_per_vessel.sort_values(ascending=False).head(10)\n",
    "\n",
    "    # Print concise overview\n",
    "    print(f\"Number of unique vessels: {num_vessels}\")\n",
    "    print(f\"Latitude range: {lat_min:.6f} -- {lat_max:.6f}\")\n",
    "    print(f\"Longitude range: {lon_min:.6f} -- {lon_max:.6f}\")\n",
    "    print(f\"Centroid (lat, lon): ({centroid_lat:.6f}, {centroid_lon:.6f})\")\n",
    "    print(\"\\nMessages per vessel (summary):\")\n",
    "    for k, v in msgs_stats.items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "    print(\"\\nTop 10 vessels by number of messages (MMSI: count):\")\n",
    "    print(top_10_vessels.to_string())\n",
    "\n",
    "\n",
    "def singularize_vessels(df, mmsi_col=\"MMSI\", start_col_index=11, join_conflicts=True, sep=\" | \"):\n",
    "    cols = list(df.columns[start_col_index:])\n",
    "    if mmsi_col not in df.columns:\n",
    "        raise KeyError(f\"MMSI column '{mmsi_col}' not found in dataframe\")\n",
    "\n",
    "    def _agg(series):\n",
    "        vals = series.dropna().unique().tolist()\n",
    "        if len(vals) == 0:\n",
    "            return np.nan\n",
    "        if len(vals) == 1:\n",
    "            return vals[0]\n",
    "        if join_conflicts:\n",
    "            return sep.join(map(str, vals))\n",
    "        return vals\n",
    "\n",
    "    grouped = df.groupby(mmsi_col)[cols].agg(_agg).reset_index()\n",
    "    ordered_cols = [mmsi_col] + cols\n",
    "    return grouped[ordered_cols]\n",
    "\n",
    "def filter_inside_square(df, bbox) -> pd.DataFrame:\n",
    "    north, west, south, east = bbox\n",
    "    df = df[(df[\"Latitude\"] <= north) & (df[\"Latitude\"] >= south) & (df[\"Longitude\"] >= west) & (df[\"Longitude\"] <= east)] \n",
    "    return df\n",
    "\n",
    "def is_inside_polygon(lat, lon, polygon_coords):\n",
    "    \"\"\"\n",
    "    Check if a point (lat, lon) is inside a polygon.\n",
    "    \n",
    "    Args:\n",
    "        lat: Latitude\n",
    "        lon: Longitude\n",
    "        polygon_coords: List of (lon, lat) tuples defining polygon vertices\n",
    "        \n",
    "    Returns:\n",
    "        Boolean: True if point is inside polygon\n",
    "    \"\"\"\n",
    "    point = Point(lat, lon)\n",
    "    polygon = Polygon(polygon_coords)\n",
    "    return polygon.contains(point)\n",
    "\n",
    "\n",
    "def extract_static_vessel_info(df, join_conflicts=True, sep=\" | \"):\n",
    "    \"\"\"\n",
    "    Extract unique vessels with their static information from AIS data.\n",
    "    Handles conflicting values by joining them or keeping as list.\n",
    "    \n",
    "    Args:\n",
    "        df: Cleaned AIS dataframe with MMSI and static columns\n",
    "        join_conflicts: If True, join conflicting values with separator. \n",
    "                       If False, keep as list.\n",
    "        sep: Separator for joining conflicting values (default: \" | \")\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with one row per unique MMSI and static columns\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define static columns\n",
    "    STATIC_COLUMNS = [\n",
    "        'MMSI',\n",
    "        'IMO',\n",
    "        'Callsign',\n",
    "        'Name',\n",
    "        'Ship type',\n",
    "        'Cargo type',\n",
    "        'Width',\n",
    "        'Length',\n",
    "        'Size A',\n",
    "        'Size B',\n",
    "        'Size C',\n",
    "        'Size D',\n",
    "    ]\n",
    "    \n",
    "    # Filter to only columns that exist in the dataframe\n",
    "    available_static_cols = [col for col in STATIC_COLUMNS if col in df.columns]\n",
    "    \n",
    "    if 'MMSI' not in df.columns:\n",
    "        raise KeyError(\"MMSI column not found in dataframe\")\n",
    "    \n",
    "    # Remove MMSI from aggregation columns (it's the groupby key)\n",
    "    agg_cols = [col for col in available_static_cols if col != 'MMSI']\n",
    "    \n",
    "    def _agg(series):\n",
    "        \"\"\"Aggregate function: handle single values, conflicts, or NaN\"\"\"\n",
    "        vals = series.dropna().unique().tolist()\n",
    "        \n",
    "        if len(vals) == 0:\n",
    "            return np.nan\n",
    "        if len(vals) == 1:\n",
    "            return vals[0]\n",
    "        # Multiple conflicting values\n",
    "        if join_conflicts:\n",
    "            return sep.join(map(str, vals))\n",
    "        return vals\n",
    "    \n",
    "    # Group by MMSI and aggregate static columns\n",
    "    static_df = df.groupby('MMSI')[agg_cols].agg(_agg).reset_index()\n",
    "    \n",
    "    # Reorder columns to have MMSI first\n",
    "    ordered_cols = ['MMSI'] + agg_cols\n",
    "    static_df = static_df[ordered_cols]\n",
    "    \n",
    "    # Add derived features\n",
    "    if 'Size A' in static_df.columns and 'Size B' in static_df.columns:\n",
    "        static_df['vessel_length'] = pd.to_numeric(static_df['Size A'], errors='coerce') + \\\n",
    "                                     pd.to_numeric(static_df['Size B'], errors='coerce')\n",
    "    \n",
    "    if 'Size C' in static_df.columns and 'Size D' in static_df.columns:\n",
    "        static_df['vessel_width'] = pd.to_numeric(static_df['Size C'], errors='coerce') + \\\n",
    "                                    pd.to_numeric(static_df['Size D'], errors='coerce')\n",
    "    \n",
    "    print(f\"‚úÖ Extracted {len(static_df)} unique vessels\")\n",
    "    print(f\"   Columns: {', '.join(static_df.columns)}\")\n",
    "    \n",
    "    # Report conflicts\n",
    "    conflict_cols = []\n",
    "    for col in agg_cols:\n",
    "        if static_df[col].astype(str).str.contains(sep, regex=False).any():\n",
    "            n_conflicts = static_df[col].astype(str).str.contains(sep, regex=False).sum()\n",
    "            conflict_cols.append(f\"{col} ({n_conflicts})\")\n",
    "    \n",
    "    if conflict_cols:\n",
    "        print(f\"   ‚ö†Ô∏è  Conflicts detected in: {', '.join(conflict_cols)}\")\n",
    "    \n",
    "    return static_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "80e26a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def df_filter( df: pd.DataFrame, print: bool) -> pd.DataFrame:\n",
    "\n",
    "    #print initial number of rows and unique vessels\n",
    "    if print:\n",
    "        print(f\" Starting filtering: {len(df):,} rows, {df['MMSI'].nunique():,} unique vessels\")\n",
    "    #initial filter on bounding box (take northest and southest, westest and eastest points):\n",
    "    bbox = [57.58, 10.5, 57.12, 11.92]  # north, west, south, east\n",
    "    # Define polygon coordinates as (lat, lon)\n",
    "    polygon_coords = [\n",
    "        (57.3500, 10.5162),  # coast top left\n",
    "        (57.5120, 10.9314),  # sea top left\n",
    "        (57.5785, 11.5128),  # sea top right\n",
    "        (57.5230, 11.9132),  # top right (Swedish coast)\n",
    "        (57.4078, 11.9189),  # bottom right (Swedish coast)\n",
    "        (57.1389, 11.2133),  # sea bottom right\n",
    "        (57.1352, 11.0067),  # sea bottom left\n",
    "        (57.1880, 10.5400),  # coast bottom left\n",
    "        (57.3500, 10.5162),  # close polygon (duplicate of first)\n",
    "    ]\n",
    "\n",
    "    df = df.rename(columns={\"# Timestamp\": \"Timestamp\"}) # Rename column for consistency\n",
    "    df[\"Timestamp\"] = pd.to_datetime(df[\"Timestamp\"], format=\"%d/%m/%Y %H:%M:%S\", errors=\"coerce\") # Convert to datetime\n",
    "\n",
    "    df = df[df[\"MMSI\"].str.len() == 9]  # Adhere to MMSI format\n",
    "    df = df[df[\"MMSI\"].str[:3].astype(int).between(200, 775)]  # Adhere to MID standard\n",
    "\n",
    "    df = df.drop_duplicates([\"Timestamp\", \"MMSI\", ], keep=\"first\") # Remove duplicates\n",
    "\n",
    "    #print how many rows and unique vessels are left after filtering\n",
    "    if print:\n",
    "        print(f\" Initial filtering complete: {len(df):,} rows, {df['MMSI'].nunique():,} unique vessels\")\n",
    "\n",
    "    # Filter based on bounding box\n",
    "    north, west, south, east = bbox\n",
    "    df = df[(df[\"Latitude\"] <= north) & (df[\"Latitude\"] >= south) & (df[\"Longitude\"] >= west) & (df[\"Longitude\"] <= east)] \n",
    "    if print:\n",
    "        print(f\" Bounding box filtering complete: {len(df):,} rows, {df['MMSI'].nunique():,} unique vessels\")\n",
    "    # Filter based on polygon\n",
    "    point = df[[\"Latitude\", \"Longitude\"]].apply(lambda x: Point(x[\"Longitude\"], x[\"Latitude\"]), axis=1)\n",
    "    polygon = Polygon(polygon_coords)\n",
    "    df = df[point.apply(lambda x: polygon.contains(x))]\n",
    "    if print:\n",
    "        print(f\" Polygon filtering complete: {len(df):,} rows, {df['MMSI'].nunique():,} unique vessels\")\n",
    "\n",
    "\n",
    "    knots_to_ms = 0.514444\n",
    "    df[\"SOG\"] = knots_to_ms * df[\"SOG\"]\n",
    "\n",
    "    return df\n",
    "\n",
    "def split_static_dynamic(df, join_conflicts=True, sep=\" | \"):\n",
    "    \"\"\"\n",
    "    Split AIS dataframe into static vessel info and dynamic trajectory data.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define column categories\n",
    "    STATIC_COLUMNS = [\n",
    "        'MMSI',\n",
    "        'IMO',\n",
    "        'Callsign',\n",
    "        'Name',\n",
    "        'Ship type',\n",
    "        'Cargo type',\n",
    "        'Width',\n",
    "        'Length',\n",
    "        'Size A',\n",
    "        'Size B',\n",
    "        'Size C',\n",
    "        'Size D',\n",
    "        'Data source type',\n",
    "        'Type of position fixing device',\n",
    "    ]\n",
    "    \n",
    "    DYNAMIC_COLUMNS = [\n",
    "        'MMSI',  # Keep as foreign key\n",
    "        'Timestamp',\n",
    "        'Type of mobile',\n",
    "        'Latitude',\n",
    "        'Longitude',\n",
    "        'Navigational status',\n",
    "        'ROT',\n",
    "        'SOG',\n",
    "        'COG',\n",
    "        'Heading',\n",
    "        'Draught',\n",
    "        'Destination',\n",
    "        'ETA',\n",
    "    ]\n",
    "    \n",
    "    if 'MMSI' not in df.columns:\n",
    "        raise KeyError(\"MMSI column not found in dataframe\")\n",
    "    \n",
    "    # 1. CREATE STATIC DATAFRAME\n",
    "    available_static = [col for col in STATIC_COLUMNS if col in df.columns]\n",
    "    agg_cols = [col for col in available_static if col != 'MMSI']\n",
    "    \n",
    "    def _agg(series):\n",
    "        vals = series.dropna().unique().tolist()\n",
    "        if len(vals) == 0:\n",
    "            return np.nan\n",
    "        if len(vals) == 1:\n",
    "            return vals[0]\n",
    "        if join_conflicts:\n",
    "            if \"Unknown\" in vals:\n",
    "                vals.remove(\"Unknown\")\n",
    "            if \"Undefined\" in vals:\n",
    "                vals.remove(\"Undefined\")\n",
    "            if len(vals) == 1:\n",
    "                return vals[0]\n",
    "            return sep.join(map(str, vals))\n",
    "        return vals\n",
    "    \n",
    "    static_df = df.groupby('MMSI')[agg_cols].agg(_agg).reset_index()\n",
    "    \n",
    "    \n",
    "    # 2. CREATE DYNAMIC DATAFRAME\n",
    "    available_dynamic = [col for col in DYNAMIC_COLUMNS if col in df.columns]\n",
    "    dynamic_df = df[available_dynamic].copy()\n",
    "    \n",
    "    # 3. REPORT\n",
    "    print(f\"Split complete:\")\n",
    "    print(f\"   Static:  {len(static_df):,} unique vessels with {len(static_df.columns)} columns\")\n",
    "    print(f\"   Dynamic: {len(dynamic_df):,} AIS messages with {len(dynamic_df.columns)} columns\")\n",
    "    \n",
    "    # Check for conflicts in static data\n",
    "    conflict_cols = []\n",
    "    for col in agg_cols:\n",
    "        if static_df[col].astype(str).str.contains(sep, regex=False).any():\n",
    "            n_conflicts = static_df[col].astype(str).str.contains(sep, regex=False).sum()\n",
    "            conflict_cols.append(f\"{col} ({n_conflicts})\")\n",
    "    \n",
    "    if conflict_cols:\n",
    "        print(f\"  Static conflicts: {', '.join(conflict_cols)}\")\n",
    "    \n",
    "    return static_df, dynamic_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9753f2d",
   "metadata": {},
   "source": [
    "# üõ∞Ô∏è AIS Data Filtering and Preprocessing ‚Äî Kattegat Submarine Cable Area\n",
    "\n",
    "This notebook documents the initial steps of data preparation for the AIS anomaly detection project focusing on the submarine communication cables in the Kattegat area (Denmark‚ÄìSweden).\n",
    "\n",
    "The goal is to isolate AIS data within a defined polygon surrounding three specific cable routes (**GC2**, **Kattegat 2A**, and **Kattegat 2B**) and perform preliminary cleaning and filtering.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b2b51d",
   "metadata": {},
   "source": [
    "## üß≠ Area of Interest Definition\n",
    "\n",
    "We are interested in identifying potential anomalous or risky vessel behaviors near submarine cables.\n",
    "\n",
    "By Danish law, a 200 m protection zone exists on each side of these cables, but in this study we extend the inspection zone to **5 km** to capture behavioral precursors such as early anchoring, trawling, or route deviations before ships enter the restricted corridor.\n",
    "\n",
    "The polygon defining our area of interest was manually approximated based on the **DKCPC map**.\n",
    "\n",
    "It includes a section of the Danish coast near Saeby and extends to the Swedish side around Lerkil, covering the main cable routes.  \n",
    "The coordinates are stored as `(latitude, longitude)` pairs and define an octagonal region enclosing the study zone.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fbd739",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial filter on bounding box (take northest and southest, westest and eastest points):\n",
    "bbox = [57.58, 10.5, 57.12, 11.92]  # north, west, south, east\n",
    "# Define polygon coordinates as (lat, lon)\n",
    "polygon_coords = [\n",
    "    (57.3500, 10.5162),  # coast top left\n",
    "    (57.5120, 10.9314),  # sea top left\n",
    "    (57.5785, 11.5128),  # sea top right\n",
    "    (57.5230, 11.9132),  # top right (Swedish coast)\n",
    "    (57.4078, 11.9189),  # bottom right (Swedish coast)\n",
    "    (57.1389, 11.2133),  # sea bottom right\n",
    "    (57.1352, 11.0067),  # sea bottom left\n",
    "    (57.1880, 10.5400),  # coast bottom left\n",
    "    (57.3500, 10.5162),  # close polygon (duplicate of first)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c018791d",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Data Loading\n",
    "\n",
    "In this step, AIS data (in CSV format) is loaded and receives a first hand cleaning 10% of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f42f82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_28 = pd.read_csv(\"aisdk-2025-10-28.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7c7078",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check how many rows are in the dataframe\n",
    "df_28.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5096e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = mini_cleaning_pipeline(df_28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dffe131",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31bc42a",
   "metadata": {},
   "source": [
    "## üìç SQUARE Filtering\n",
    "\n",
    "The box coordinates defined earlier are used to filter the AIS dataset.\n",
    "Each point is checked to determine whether it falls inside the box using simple operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bee294",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inside_square = filter_inside_square(df_cleaned, bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96823bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inside_square.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bcd40e",
   "metadata": {},
   "source": [
    "## üìç Polygon Filtering\n",
    "\n",
    "The polygon coordinates defined earlier are used to filter the AIS dataset.\n",
    "\n",
    "Each point is checked to determine whether it falls inside the polygon using geometric operations (e.g. with the `shapely` library).\n",
    "\n",
    "The resulting dataset contains only positions **within the defined Kattegat zone**, roughly **3‚Äì4 %** of the original AIS dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb9703c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_katt_2 = df_inside_square[\n",
    "    df_inside_square.apply(lambda row: is_inside_polygon(row['Latitude'], row['Longitude'], polygon_coords), axis=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee428d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_katt_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1aae5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here import directly the cleaned one from csv\n",
    "df_katt = pd.read_csv(\"df_28_katt.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69df1ab7",
   "metadata": {},
   "source": [
    "## üìä Data Overview After Filtering\n",
    "\n",
    "We summarize the filtered dataset:\n",
    "\n",
    "- Number of unique vessels  \n",
    "- Time coverage of the subset  \n",
    "- Spatial extent and approximate number of messages per vessel  \n",
    "\n",
    "This quick overview helps confirm that the filtering worked as expected and that the dataset is representative of the study area.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c77ae63",
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_summary(df_katt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43968802",
   "metadata": {},
   "source": [
    "# USING SUMMARY FUNCTIONS TO FILTER AND DIVIDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0aa54a85",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "df_filter() got an unexpected keyword argument 'pr'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[106]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df_filtered = \u001b[43mdf_filter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_28\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpr\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: df_filter() got an unexpected keyword argument 'pr'"
     ]
    }
   ],
   "source": [
    "df_filtered = df_filter(df_28, pr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d7d81267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Split complete:\n",
      "   Static:  173 unique vessels with 10 columns\n",
      "   Dynamic: 322,988 AIS messages with 13 columns\n",
      "   ‚ö†Ô∏è  Static conflicts: Type of position fixing device (1)\n"
     ]
    }
   ],
   "source": [
    "df_static, df_dynamic = split_static_dynamic(df_filtered, join_conflicts=True, sep=\" | \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8dc4333d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "MMSI",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "IMO",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Callsign",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Name",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Ship type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Cargo type",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Width",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Length",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Data source type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Type of position fixing device",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "8277ae49-3e7e-404c-90a0-c281eef4a8c7",
       "rows": [
        [
         "0",
         "2190073",
         "Unknown",
         "Unknown",
         null,
         "Undefined",
         null,
         null,
         null,
         "AIS",
         "GPS"
        ],
        [
         "1",
         "111219510",
         "Unknown",
         "0",
         null,
         "SAR",
         null,
         "5.0",
         "20.0",
         "AIS",
         "GPS"
        ],
        [
         "2",
         "111265121",
         "Unknown",
         "Unknown",
         "FFK STC 121",
         "Reserved",
         null,
         "10.0",
         "8.0",
         "AIS",
         "Undefined"
        ],
        [
         "3",
         "209114000",
         "9173185",
         "5BQN4",
         "RIX AMETHYST",
         "Cargo",
         null,
         "12.0",
         "89.0",
         "AIS",
         "Internal"
        ],
        [
         "4",
         "209903000",
         "9975753",
         "5BHK6",
         "CEMCOMMANDER",
         "Cargo",
         "No additional information",
         "15.0",
         "113.0",
         "AIS",
         "GPS"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MMSI</th>\n",
       "      <th>IMO</th>\n",
       "      <th>Callsign</th>\n",
       "      <th>Name</th>\n",
       "      <th>Ship type</th>\n",
       "      <th>Cargo type</th>\n",
       "      <th>Width</th>\n",
       "      <th>Length</th>\n",
       "      <th>Data source type</th>\n",
       "      <th>Type of position fixing device</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2190073</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Undefined</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AIS</td>\n",
       "      <td>GPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111219510</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SAR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>AIS</td>\n",
       "      <td>GPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>111265121</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>FFK STC 121</td>\n",
       "      <td>Reserved</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>AIS</td>\n",
       "      <td>Undefined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>209114000</td>\n",
       "      <td>9173185</td>\n",
       "      <td>5BQN4</td>\n",
       "      <td>RIX AMETHYST</td>\n",
       "      <td>Cargo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>AIS</td>\n",
       "      <td>Internal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>209903000</td>\n",
       "      <td>9975753</td>\n",
       "      <td>5BHK6</td>\n",
       "      <td>CEMCOMMANDER</td>\n",
       "      <td>Cargo</td>\n",
       "      <td>No additional information</td>\n",
       "      <td>15.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>AIS</td>\n",
       "      <td>GPS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MMSI      IMO Callsign          Name  Ship type  \\\n",
       "0    2190073  Unknown  Unknown           NaN  Undefined   \n",
       "1  111219510  Unknown        0           NaN        SAR   \n",
       "2  111265121  Unknown  Unknown   FFK STC 121   Reserved   \n",
       "3  209114000  9173185    5BQN4  RIX AMETHYST      Cargo   \n",
       "4  209903000  9975753    5BHK6  CEMCOMMANDER      Cargo   \n",
       "\n",
       "                  Cargo type  Width  Length Data source type  \\\n",
       "0                        NaN    NaN     NaN              AIS   \n",
       "1                        NaN    5.0    20.0              AIS   \n",
       "2                        NaN   10.0     8.0              AIS   \n",
       "3                        NaN   12.0    89.0              AIS   \n",
       "4  No additional information   15.0   113.0              AIS   \n",
       "\n",
       "  Type of position fixing device  \n",
       "0                            GPS  \n",
       "1                            GPS  \n",
       "2                      Undefined  \n",
       "3                       Internal  \n",
       "4                            GPS  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_static.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f81fd3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
