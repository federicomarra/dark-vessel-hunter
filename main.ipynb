{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e568f0d6",
   "metadata": {},
   "source": [
    "# dark-vessel-hunter\n",
    "DTU Deep Learning project 29, group 80"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425814a0",
   "metadata": {},
   "source": [
    "\n",
    "### Run this in your terminal before executing this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6f609e",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd8b671",
   "metadata": {},
   "source": [
    "## Import of the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0a993f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ais_downloader\n",
    "import ais_filtering\n",
    "import ais_reader\n",
    "import ais_to_parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccd44da",
   "metadata": {},
   "source": [
    "## Data setup\n",
    "### Set data preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5cdbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_DATE = \"2025-11-01\"\n",
    "END_DATE   = \"2025-11-02\"\n",
    "\n",
    "FOLDER_NAME = \"ais-data\"\n",
    "OUTPUT_FOLDER_NAME = \"ais-data-parquet\"\n",
    "DELETE_DOWNLOADED_CSV = False\n",
    "verbose_mode = True\n",
    "\n",
    "vessel_ais_class = (\"Class A\", \"Class B\")\n",
    "min_segment_length = 256\n",
    "\n",
    "# Bounding Box to prefilter AIS data [lat_max, lon_min, lat_min, lon_max]\n",
    "bbox = [57.58, 10.5, 57.12, 11.92]\n",
    "\n",
    "# Polygon coordinates for precise Area of Interest (AOI) filtering (lon, lat)\n",
    "polygon_coords = [\n",
    "    (10.5162, 57.3500),  # coast top left (lon, lat)\n",
    "    (10.9314, 57.5120),  # sea top left\n",
    "    (11.5128, 57.5785),  # sea top right\n",
    "    (11.9132, 57.5230),  # top right (Swedish coast)\n",
    "    (11.9189, 57.4078),  # bottom right (Swedish coast)\n",
    "    (11.2133, 57.1389),  # sea bottom right\n",
    "    (11.0067, 57.1352),  # sea bottom left\n",
    "    (10.5400, 57.1880),  # coast bottom left\n",
    "    (10.5162, 57.3500),  # close polygon\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d18fd6d",
   "metadata": {},
   "source": [
    "### Imports for the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc178db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from datetime import date, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9d8db5",
   "metadata": {},
   "source": [
    "### Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a99188",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:   0%|          | 0/2 [00:00<?, ?file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing date: 2025-11-01\n",
      "Skipping 2025-11-01 download: already present in ais-data folder\n",
      " Read AIS data: 988,647 rows within bbox,  241 unique vessels\n",
      " [filter_ais_df] Before filtering: 988,647 rows,  [filter_ais_df] 241 unique vessels\n",
      " [filter_ais_df] Type of mobile filtering complete: 950,987 rows  [filter_ais_df] (removed 37,660 rows)  [filter_ais_df] using types: ['Class A', 'Class B']\n",
      " [filter_ais_df] MMSI filtering complete: 950,965 rows,  [filter_ais_df] 238 unique vessels\n",
      " [filter_ais_df] Duplicate removal complete: 535,909 rows,  [filter_ais_df] 238 unique vessels\n",
      " [filter_ais_df] Polygon filtering complete: 276,112 rows,  [filter_ais_df] 176 unique vessels\n",
      " [segment_ais_tracks] Starting with 276,112 rows,  176 unique vessels\n",
      " [segment_ais_tracks] After MMSI-level filter: 100,223 rows,  124 vessels\n",
      " [segment_ais_tracks] After segment-level filter: 98,101 rows,  131 segments\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:  50%|█████     | 1/2 [01:11<01:11, 71.71s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [save_by_mmsi] Parquet dataset written/appended at: D:\\Projects\\dark-vessel-hunter\\ais-data-parquet\n",
      "\n",
      "Processing date: 2025-11-02\n",
      "Starting download and extraction for 2025-11-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 2025-11-02 zip file: 100%|██████████| 536M/536M [00:26<00:00, 21.6MB/s]\n",
      "Unzipping into ais-data folder : 100%|██████████| 1/1 [00:49<00:00, 49.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed download and extraction for 2025-11-02\n",
      " Read AIS data: 933,867 rows within bbox,  226 unique vessels\n",
      " [filter_ais_df] Before filtering: 933,867 rows,  [filter_ais_df] 226 unique vessels\n",
      " [filter_ais_df] Type of mobile filtering complete: 895,249 rows  [filter_ais_df] (removed 38,618 rows)  [filter_ais_df] using types: ['Class A', 'Class B']\n",
      " [filter_ais_df] MMSI filtering complete: 895,249 rows,  [filter_ais_df] 225 unique vessels\n",
      " [filter_ais_df] Duplicate removal complete: 500,728 rows,  [filter_ais_df] 225 unique vessels\n",
      " [filter_ais_df] Polygon filtering complete: 259,909 rows,  [filter_ais_df] 152 unique vessels\n",
      " [segment_ais_tracks] Starting with 259,909 rows,  152 unique vessels\n",
      " [segment_ais_tracks] After MMSI-level filter: 137,425 rows,  112 vessels\n",
      " [segment_ais_tracks] After segment-level filter: 135,132 rows,  122 segments\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data: 100%|██████████| 2/2 [03:19<00:00, 99.52s/file] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [save_by_mmsi] Parquet dataset written/appended at: D:\\Projects\\dark-vessel-hunter\\ais-data-parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Create folder path ---\n",
    "folder_path = Path(FOLDER_NAME)\n",
    "folder_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- If you want to download all csv files before, uncomment the line below ---\n",
    "# ais_downloader.download_multiple_ais_data(START_DATE, END_DATE, folder_path)\n",
    "\n",
    "# --- Build the schedule of download string dates ---\n",
    "dates = ais_downloader.get_work_dates(START_DATE, END_DATE, folder_path, filter=False)\n",
    "\n",
    "# --- Define separator for conflicting data ---\n",
    "# separator = \" | \"\n",
    "\n",
    "# --- Iterate with tqdm and download, unzip and delete ---\n",
    "for day in tqdm(dates, desc=f\"Processing data\", unit=\"file\" ):\n",
    "    tag = f\"{day:%Y-%m}\" if day < date.fromisoformat(\"2024-03-01\") else f\"{day:%Y-%m-%d}\"\n",
    "    print(f\"\\nProcessing date: {tag}\")\n",
    "\n",
    "    # --- Download one day ---\n",
    "    csv_path = ais_downloader.download_one_ais_data(day, folder_path)\n",
    "    \n",
    "    # --- Load CSV into DataFrame ---\n",
    "    df_raw = ais_reader.read_single_ais_df(csv_path, bbox, verbose=verbose_mode)\n",
    "    # --- Optionally delete the downloaded CSV file ---\n",
    "    if DELETE_DOWNLOADED_CSV: csv_path.unlink(missing_ok=True)\n",
    "    \n",
    "    # --- Filter and split ---\n",
    "    # Filter AIS data, keeping Class A and Class B by default,\n",
    "    df_filtered = ais_filtering.filter_ais_df(\n",
    "        df_raw,\n",
    "        polygon_coords,\n",
    "        allowed_mobile_types= vessel_ais_class,\n",
    "        verbose=verbose_mode,\n",
    "    )\n",
    "\n",
    "    # df_filtered = ais_filtering.df_filter(df_raw, verbose_mode=True, polygon_filter=True)\n",
    "    \n",
    "    # print(df_filtered.head()) # For debugging purposes to see the filtered data\n",
    "    # df_static, df_dynamic = ais_filtering.split_static_dynamic(df_filtered, join_conflicts=True, sep=separator)\n",
    "    \n",
    "    # --- Save to parquet ---\n",
    "    # ais_to_parquet.save_by_mmsi(df_static, df_dynamic, folder_path, tag)\n",
    "\n",
    "    df_seg = ais_to_parquet.segment_ais_tracks(df_filtered, min_track_len=min_segment_length, verbose=verbose_mode)\n",
    "    ais_to_parquet.save_by_mmsi(df_seg, verbose=verbose_mode, output_folder=OUTPUT_FOLDER_NAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
